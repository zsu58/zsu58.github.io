---
title: "[Apache Airflow] Airflow - MySQL Data Extract"
layout: single
date: '12/01/2022'
toc: true
toc_sticky: true
toc_label: Table of Contents
categories:
  - AIRFLOW
tags:
  - AIRFLOW
  - DOCKER
---

---
### Airflow - MySQL Data Extract
* Required Package Installation
* Airflow - MySQL(local on Docker) Extract
* Airflow - MySQL(EC2) Extract

---

### Required Package Installation
* mysqlì€ homebrewë¥¼ í†µí•´ ì„¤ì¹˜ ë° .zshrcì— í™˜ê²°ì„¤ì • ë“±ë¡

```bash
# venv ì‹¤í–‰ í›„
pip3 install mysql-connector-python
pip3 install mysqlclient
pip3 install apache-airflow-providers-mysql

# mysql provider ì„¤ì¹˜ í™•ì¸
airflow providers list
```
---

### Airflow - MySQL(local on Docker) Extract

```python
from datetime import datetime

from airflow.models import DAG
from airflow.sensors.sql import SqlSensor
from airflow.hooks.mysql_hook import MySqlHook
from airflow.operators.python import PythonOperator

import pandas as pd

def _extract_member_from_mysql():
    # Get hook
    mysql_server = MySqlHook(mysql_conn_id="mysql_conn")
    # Execute query
    df = mysql_server.get_pandas_df(sql="SELECT * FROM member;")

    # Generate unique filename
    base_file_path = "tmp/member"
    path = "{}_{}.csv".format(base_file_path, datetime.now().strftime("%Y-%m-%d-%H-%M-%S"))
    # save file
    df.to_csv(path, index=False)

with DAG(
    "member_processing",
    schedule_interval="@daily",
    start_date=datetime(2022,1,11),
    catchup=False
) as dag:

    # check sql
    is_sql_available = SqlSensor(
        task_id="is_sql_available",
        conn_id="mysql_conn",
        sql="SELECT * FROM member;"
    )

    # extract data from mysql
    extract_member_mysql = PythonOperator(
        task_id="extract_member_mysql",
        python_callable=_extract_member_from_mysql
    )

is_sql_available >> extract_member_mysql
```

* Add Connection in Airflow Webserver

```bash
# airflow webserver - Admin - Connections - + (ì¶”ê°€)
# 1) Conn Id: python dagíŒŒì¼ì˜ mysql_conn_id ì´ë¦„
mysql_conn
# 2) Conn Type: í•´ë‹¹í•˜ëŠ” connection
MySQL
# 3) description: ììœ ë¡­ê²Œ ì‘ì„±
Connection to local MySQL
# 4) Host:
0.0.0.0
# 5) Schema: DB ìŠ¤í‚¤ë§ˆ
airflow
# 6) Login: DB id
root
# 7) Password: DB password 
1234
# 8) Port:
3306
# í™•ì¸
```
---

### Airflow - MySQL(EC2) Extract
* ìœ„ì—ì„œ mysql_conn_idë§Œ ë°”ê¾¸ê¸°

```python
...
def _extract_member_from_mysql():
    # Get hook
    mysql_server = MySqlHook(mysql_conn_id="ec2_mysql_conn")
...
with DAG(
    "ec2_member_processing",
...
) as dag:

    is_sql_available = SqlSensor(
        ...
        conn_id="ec2_mysql_conn",
        ...
    )
...

is_sql_available >> extract_member_mysql
```

* Add Connection in Airflow Webserver

```bash
# airflow webserver - Admin - Connections - + (ì¶”ê°€)
# 1) Conn Id: python dagíŒŒì¼ì˜ mysql_conn_id ì´ë¦„
ec2_mysql_conn
# 2) Conn Type: í•´ë‹¹í•˜ëŠ” connection
MySQL
# 3) description: ììœ ë¡­ê²Œ ì‘ì„±
Connection to ec2 MySQL
# 4) Host:
ec2-15-164-164-229.ap-northeast-2.compute.amazonaws.com
# 5) Schema: DB ìŠ¤í‚¤ë§ˆ
airflow
# 6) Login: DB id
jisu
# 7) Password: DB password 
********
# 8) Port:
3306
# í™•ì¸
```
---

### ref 
* [ğŸ”— apache-airflow-providers-mysql ì„¤ì¹˜](https://airflow.apache.org/docs/apache-airflow-providers-mysql/stable/index.html)
* [ğŸ”— MySQLOperator ê³µì‹ë¬¸ì„œ](https://airflow.apache.org/docs/apache-airflow-providers-mysql/stable/operators.html)
* [ğŸ”— MySQLOperator ì˜ˆì œ ê³µì‹ë¬¸ì„œ](https://airflow.apache.org/docs/apache-airflow-providers-mysql/stable/_modules/airflow/providers/mysql/example_dags/example_mysql.html)
* [ğŸ”— ì°¸ê³ ë¸”ë¡œê·¸1](https://www.codestudyblog.com/cnb2004/0412094950.html)
* [ğŸ”— ì°¸ê³ ë¸”ë¡œê·¸2](https://www.astronomer.io/guides/airflow-sql-tutorial)
* [ğŸ”— ì°¸ê³ ìë£Œ1](https://stackoverflow.com/questions/61555430/how-to-do-store-sql-output-to-pandas-dataframe-using-airflow)


