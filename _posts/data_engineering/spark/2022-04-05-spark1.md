---
title: "[Spark] SPARK ê°œë… ì •ë¦¬"
layout: single
date: '5/4/2022'
toc: true
toc_sticky: true
toc_label: Table of Contents
categories:
  - SPARK
tags:
  - SPARK
---

---
### SPARK ê°œë… ì •ë¦¬
* Glossary
* Spark Cluster Mode Overview
* Spark-Submit ì‹¤í–‰ìˆœì„œ
* YARNì—ì„œì˜ ì‹¤í–‰
  * YARN Cluster Mode
  * YARN Client Mode
* Deployment Mode Summary

---

#### Glossary
<table class="table">
  <thead>
    <tr><th style="width: 130px;">Term</th><th>Meaning</th></tr>
  </thead>
  <tbody>
    <tr>
      <td>Application</td>
      <td>User program built on Spark. Consists of a <em>driver program</em> and <em>executors</em> on the cluster.</td>
    </tr>
    <tr>
      <td>Application jar</td>
      <td>
        A jar containing the user's Spark application. In some cases users will want to create
        an "uber jar" containing their application along with its dependencies. The user's jar
        should never include Hadoop or Spark libraries, however, these will be added at runtime.
      </td>
    </tr>
    <tr>
      <td>Driver program</td>
      <td>The process running the main() function of the application and creating the SparkContext</td>
    </tr>
    <tr>
      <td>Cluster manager</td>
      <td>An external service for acquiring resources on the cluster (e.g. standalone manager, Mesos, YARN, Kubernetes)</td>
    </tr>
    <tr>
      <td>Deploy mode</td>
      <td>Distinguishes where the driver process runs. In "cluster" mode, the framework launches
        the driver inside of the cluster. In "client" mode, the submitter launches the driver
        outside of the cluster.</td>
    </tr>
    <tr>
      <td>Worker node</td>
      <td>Any node that can run application code in the cluster</td>
    </tr>
    <tr>
      <td>Executor</td>
      <td>A process launched for an application on a worker node, that runs tasks and keeps data in memory
        or disk storage across them. Each application has its own executors.</td>
    </tr>
    <tr>
      <td>Task</td>
      <td>A unit of work that will be sent to one executor</td>
    </tr>
    <tr>
      <td>Job</td>
      <td>A parallel computation consisting of multiple tasks that gets spawned in response to a Spark action
        (e.g. <code>save</code>, <code>collect</code>); you'll see this term used in the driver's logs.</td>
    </tr>
    <tr>
      <td>Stage</td>
      <td>Each job gets divided into smaller sets of tasks called <em>stages</em> that depend on each other
        (similar to the map and reduce stages in MapReduce); you'll see this term used in the driver's logs.</td>
    </tr>
  </tbody>
</table>
---

#### Spark Cluster Mode Overview
* Spark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program (called the driver program)
* Specifically, to run on a cluster, the SparkContext can connect to several types of cluster managers(Standalone, Mesos, YARN or Kubernetes), which allocate resources across applications
* Once connected, Spark acquires executors on nodes in the cluster, which are processes that run computations and store data for your application
* Next, it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors
* Finally, SparkContext sends tasks to the executors to run

<p align="center">
    <img src="/img/data_engineering/spark/spark_cluster.png" align="center">
</p>

---

#### Spark-Submit ì‹¤í–‰ìˆœì„œ
* 1) $SPARK_HOME/bin/spark-submitì„ ì´ìš©í•˜ì—¬ Application ì œì¶œ
* 2) Driver Programì´ ì‹¤í–‰ë˜ë©°(main()í•¨ìˆ˜ ì‹¤í–‰) & SparkContextê°€ ìƒì„±(ì¦‰, Spark Clusterì™€ì˜ ì—°ê²°ì´ ì´ë£¨ì–´ì§)
* 3) Driverê°€ Cluster Manager(Standalone, Mesos, YARN, Kubernetes)ì—ê²Œ Executor ë¦¬ì†ŒìŠ¤ ìš”ì²­
* 4) Cluster Managerê°€ Worker (Node)ì—ê²Œ Executor ë„ìš°ë„ë¡ ëª…ë ¹
* 5) Driver Programì´ DAG Schedulingì„ í†µí•´ ì‘ì—…ì„ Task ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ Executorì—ê²Œ í• ë‹¹
* 6) Executorê°€ ì—¬ëŸ¬ ìŠ¤ë ˆë“œì—ì„œ Taskë“¤ì„ ì‹¤í–‰í•œ í›„ ê²°ê³¼ë¥¼ Driver Programì—ê²Œ ë³´ëƒ„
* 7) Applicationì´ ì™„ë£Œë˜ë©´ì„œ ë¦¬ì†ŒìŠ¤ë¥¼ Cluster Managerì—ê²Œ ë°˜í™˜

---

#### YARNì—ì„œì˜ ì‹¤í–‰
* When Spark applications run on a YARN cluster manager, resource management, scheduling, and security are controlled by YARN.
* In YARN, each application instance has an ApplicationMaster process, which is the first container started for that application.
* The application is responsible for requesting resources from the ResourceManager. 
* Once the resources are allocated, the application instructs NodeManagers to start containers on its behalf. 
* ApplicationMasters eliminate the need for an active client: the process starting the application can terminate, and coordination continues from a process managed by YARN running on the cluster.

##### YARN Cluster Mode
* Spark driver runs in the ApplicationMaster on a cluster host.
* A single process in a YARN container is responsible for both driving the application and requesting resources from YARN. 
* The client that launches the application does not need to run for the lifetime of the application.

<p align="center">
    <img src="/img/data_engineering/spark/spark_yarn_cluster.png" align="center">
</p>

##### YARN Client Mode
* Spark driver runs on the host where the job is submitted
* The ApplicationMaster is responsible only for requesting executor containers from YARN
* After the containers start, the client communicates with the containers to schedule work

<p align="center">
    <img src="/img/data_engineering/spark/spark_yarn_client.png" align="center">
</p>

---

### Deployment Mode Summary

<table id="deployment_modes__table_qqq_pbf_2s" class="table">
<caption xmlns="http://www.w3.org/1999/xhtml"><span class="tablecap"><span class="tablecap">Deployment Mode Summary</span></span></caption>
<thead class="thead" align="left">
<tr class="row">
<th class="entry" valign="top" id="d4066467e111">Mode</th>
<th class="entry" valign="top" id="d4066467e117">YARN Cluster Mode</th>
<th class="entry" valign="top" id="d4066467e114">YARN Client Mode</th>
<th class="entry" valign="top" id="d4066467e117">Spark Standalone</th>
</tr>
</thead>
<tbody class="tbody">
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Driver runs in</strong></td>
<td class="entry" valign="top" headers="d4066467e117">ApplicationMaster</td>
<td class="entry" valign="top" headers="d4066467e114">Client</td>
<td class="entry" valign="top" headers="d4066467e114">Client</td>
</tr>
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Requests resources</strong></td>
<td class="entry" valign="top" headers="d4066467e117">ApplicationMaster</td>
<td class="entry" valign="top" headers="d4066467e114">ApplicationMaster</td>
<td class="entry" valign="top" headers="d4066467e114">Client</td>
</tr>
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Starts executor processes</strong></td>
<td class="entry" valign="top" headers="d4066467e117">YARN NodeManager</td>
<td class="entry" valign="top" headers="d4066467e114">YARN NodeManager</td>
<td class="entry" valign="top" headers="d4066467e114">Spark Workers(Slaves)</td>
</tr>
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Persistent services</strong></td>
<td class="entry" valign="top" headers="d4066467e114">YARN ResourceManager and NodeManagers</td>
<td class="entry" valign="top" headers="d4066467e117">YARN ResourceManager and NodeManagers</td>
<td class="entry" valign="top" headers="d4066467e117">Spark Masters & Workers</td>
</tr>
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Supports Spark Shell</strong></td>
<td class="entry" valign="top" headers="d4066467e117">No</td>
<td class="entry" valign="top" headers="d4066467e114">Yes</td>
<td class="entry" valign="top" headers="d4066467e114">Yes</td>
</tr>
</tbody>
</table>

---

### ref
* [ğŸ”— SPARK ê³µì‹ë¬¸ì„œ](https://spark.apache.org/docs/latest/cluster-overview.html)
* [ğŸ”— SPARK Configuration](https://spark.apache.org/docs/latest/configuration.html)
* [ğŸ”— Cloudera ë¸”ë¡œê·¸](https://docs.cloudera.com/documentation/enterprise/latest/topics/cdh_ig_running_spark_on_yarn.html)
* [ğŸ”— ì°¸ê³  ë¸”ë¡œê·¸](https://12bme.tistory.com/437)
* [ğŸ”— ì°¸ê³  ë¸”ë¡œê·¸2](http://incredible.ai/spark/2016/02/11/Spark-YARN-Cluster/)
* [ğŸ”— ì°¸ê³  ë¸”ë¡œê·¸3](https://paranwater.tistory.com/417)
* [ğŸ”— ì°¸ê³  ë¸”ë¡œê·¸4](https://wooono.tistory.com/58)
