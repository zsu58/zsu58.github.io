I"Ü<hr />
<h3 id="airflow-dag">Airflow Dag</h3>
<ul>
  <li>Airflow Dag
    <ul>
      <li>Create Airflow Dag File</li>
      <li>Add Connection in Airflow Webserver</li>
      <li>Test Airflow Task</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="create-airflow-dag-file">Create Airflow Dag File</h3>
<ul>
  <li>path - AIRFLOW_HOME/dag/user_processing.py</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># user_processing.py
</span><span class="kn">from</span> <span class="nn">airflow.models</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">airflow.providers.sqlite.operators.sqlite</span> <span class="kn">import</span> <span class="n">SqliteOperator</span>

<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"start_date"</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
    <span class="s">'user_processing'</span><span class="p">,</span>
    <span class="n">schedule_interval</span><span class="o">=</span><span class="s">'@daily'</span><span class="p">,</span>
    <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
    <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
    <span class="c1"># Transfer Operator
</span>    <span class="n">creating_table</span> <span class="o">=</span> <span class="n">SqliteOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s">"creating_table"</span><span class="p">,</span>
        <span class="n">sqlite_conn_id</span><span class="o">=</span><span class="s">"db_sqlite"</span><span class="p">,</span>
        <span class="n">sql</span><span class="o">=</span><span class="s">"""
            CREATE TABLE users (
                firstname TEXT NOT NULL,
                lastname TEXT NOT NULL,
                country TEXT NOT NULL,
                username TEXT NOT NULL,
                password TEXT NOT NULL,
                email TEXT NOT NULL PRIMARY KEY
            );
            """</span>
    <span class="p">)</span>
</code></pre></div></div>
<hr />

<h3 id="add-connectionprovider-in-airflow-webserver">Add Connection(Provider) in Airflow Webserver</h3>
<ul>
  <li>Sqlite Connectionì„ ìœ„í•œ provider(python package) ì„¤ì¹˜
    <ul>
      <li>A provider is an an independent python package that brings everything your need to interact with a service or a tool such as Spark or AWS</li>
      <li>A provider contains types, operators, hooks and so on</li>
      <li>Can check installed provider with <code class="language-plaintext highlighter-rouge">airflow providers list</code></li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install</span> <span class="s1">'apache-airflow-providers-sqlite'</span>

<span class="c"># airflow webserver - Admin - Connections - + (ì¶”ê°€)</span>
<span class="c"># 1) Conn Id: python dagíŒŒì¼ì˜ sqlite_conn_id ì´ë¦„</span>
db_sqlite 
<span class="c"># 2) Conn Type: í•´ë‹¹í•˜ëŠ” connection</span>
Sqlite
<span class="c"># 3) description: ììœ ë¡­ê²Œ ì‘ì„±</span>
sqlite connection to the db
<span class="c"># 4) Host: airflow.dbì˜ path</span>
/Users/jisu/Dropbox_Carl/Dropbox/JISU/Data/DE/airflow1/airflow.db
<span class="c"># í™•ì¸</span>
</code></pre></div></div>
<hr />

<h3 id="test-airflow-task">Test Airflow Task</h3>
<ul>
  <li>allows to test a specific task
    <ul>
      <li>1) without checking for dependencies</li>
      <li>2) neither storing any medata related to the task</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># test my task (airflow tasks test [py_file] [dag_name] [execution_date])</span>
airflow tasks <span class="nb">test </span>user_processing creating_table 2022-01-07

<span class="c"># sqlite3 shell</span>
sqlite3 airflow.db

<span class="c"># list all tables to check whether the table is successfully added</span>
.tables

<span class="c"># execute a sql command to check data</span>
SELECT <span class="k">*</span> FROM <span class="nb">users</span><span class="p">;</span>
</code></pre></div></div>
<hr />

<h3 id="ref">ref</h3>
<ul>
  <li><a href="https://airflow.apache.org/docs/apache-airflow-providers/packages-ref.html">ğŸ”— Airflow-Provider ê³µì‹ë¬¸ì„œ</a></li>
</ul>
:ET